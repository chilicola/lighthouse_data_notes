{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of sales\n",
    "\n",
    "### Problem Statement\n",
    "This dataset represents sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store are available. The aim is to build a predictive model and find out the sales of each product at a particular store.\n",
    "\n",
    "|Variable|Description|\n",
    "|: ------------- |:-------------|\n",
    "|Item_Identifier|Unique product ID|\n",
    "|Item_Weight|Weight of product|\n",
    "|Item_Fat_Content|Whether the product is low fat or not|\n",
    "|Item_Visibility|The % of total display area of all products in a store allocated to the particular product|\n",
    "|Item_Type|The category to which the product belongs|\n",
    "|Item_MRP|Maximum Retail Price (list price) of the product|\n",
    "|Outlet_Identifier|Unique store ID|\n",
    "|Outlet_Establishment_Year|The year in which store was established|\n",
    "|Outlet_Size|The size of the store in terms of ground area covered|\n",
    "|Outlet_Location_Type|The type of city in which the store is located|\n",
    "|Outlet_Type|Whether the outlet is just a grocery store or some sort of supermarket|\n",
    "|Item_Outlet_Sales|Sales of the product in the particulat store. This is the outcome variable to be predicted.|\n",
    "\n",
    "Please note that the data may have missing values as some stores might not report all the data due to technical glitches. Hence, it will be required to treat them accordingly.\n",
    "\n",
    "\n",
    "\n",
    "### Explore the problem in following stages:\n",
    "\n",
    "1. Hypothesis Generation – understanding the problem better by brainstorming possible factors that can impact the outcome\n",
    "2. Data Exploration – looking at categorical and continuous feature summaries and making inferences about the data.\n",
    "3. Data Cleaning – imputing missing values in the data and checking for outliers\n",
    "4. Feature Engineering – modifying existing variables and creating new ones for analysis\n",
    "5. Model Building – making predictive models on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_num.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_num = df.dtypes[df.dtypes != object].index.tolist()\n",
    "df = df[cols_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Item_Weight_missing</th>\n",
       "      <th>Outlet_Size_missing</th>\n",
       "      <th>Year_Op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>1999</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3735.1380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.92</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>443.4228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>1999</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2097.2700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>732.3800</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>1987</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>994.7052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Fat_Content  Item_Visibility  Item_MRP  \\\n",
       "0         9.30                 1         0.016047  249.8092   \n",
       "1         5.92                 2         0.019278   48.2692   \n",
       "2        17.50                 1         0.016760  141.6180   \n",
       "3        19.20                 2         0.000000  182.0950   \n",
       "4         8.93                 0         0.000000   53.8614   \n",
       "\n",
       "   Outlet_Establishment_Year  Outlet_Size  Outlet_Location_Type  \\\n",
       "0                       1999            2                     1   \n",
       "1                       2009            2                     3   \n",
       "2                       1999            2                     1   \n",
       "3                       1998            0                     3   \n",
       "4                       1987            3                     3   \n",
       "\n",
       "   Item_Outlet_Sales  Item_Weight_missing  Outlet_Size_missing  Year_Op  \n",
       "0          3735.1380                    0                    0       22  \n",
       "1           443.4228                    0                    0       12  \n",
       "2          2097.2700                    0                    0       22  \n",
       "3           732.3800                    0                    1       23  \n",
       "4           994.7052                    0                    0       34  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have covered data preparation and feature engineering two weeks ago. Now, it's time to do some predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "## Task\n",
    "Make a baseline model. Baseline models help us set a benchmark to gauge the performance of our future models. If your new model is below the baseline, something has gone wrong, and you should check your data.\n",
    "\n",
    "To make a baseline model, run a simple regression model without altering the default parameters in sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']].values\n",
    "y = df['Item_Outlet_Sales'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8523, 4)\n",
      "(8523,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34232626984602577"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression score (baseline)\n",
    "linreg.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Split your data in 80% train set and 20% test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Use grid_search to find the best value of the parameter `alpha` for Ridge and Lasso regressions from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "params = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Ridge(),\n",
       "             param_grid={'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                   0.9]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "clf_ridge = GridSearchCV(estimator=Ridge(), param_grid=params)\n",
    "clf_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34413874500926755"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the accuracy score\n",
    "clf_ridge.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha:  0.1\n"
     ]
    }
   ],
   "source": [
    "# view the best parameters for the model found using grid search\n",
    "print('Best alpha: ', clf_ridge.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Lasso(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                   0.9]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso grid search\n",
    "from sklearn.linear_model import Lasso\n",
    "clf_lasso = GridSearchCV(estimator=Lasso(), param_grid=params, n_jobs=-1)\n",
    "clf_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3441374897075871"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the accuracy score\n",
    "clf_lasso.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha:  0.1\n"
     ]
    }
   ],
   "source": [
    "# view the best parameters for the model found using grid search\n",
    "print('Best alpha: ', clf_lasso.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Using the model from grid_search, predict the values in the test set and compare against your benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33207596239555404"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge\n",
    "y_pred_ridge = clf_ridge.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "r2_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3320878802379684"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso\n",
    "y_pred_lasso = clf_lasso.predict(X_test)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "r2_lasso"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
