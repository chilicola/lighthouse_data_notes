{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Topic Modeling Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Guide](https://blog.mlreview.com/topic-modeling-with-scikit-learn-e80d33668730)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:12.932082Z",
     "start_time": "2020-04-29T12:18:12.200358Z"
    }
   },
   "outputs": [],
   "source": [
    "# import TfidfVectorizer and CountVectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# import fetch_20newsgroups from sklearn.datasets\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# import NMF and LatentDirichletAllocation from sklearn\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:14.463840Z",
     "start_time": "2020-04-29T12:18:13.020189Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create a variable called `'no_features'` and set its value to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:15.590700Z",
     "start_time": "2020-04-29T12:18:15.585820Z"
    }
   },
   "outputs": [],
   "source": [
    "no_features = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create a variable `'no_topics'` and set its value to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:16.743304Z",
     "start_time": "2020-04-29T12:18:16.737763Z"
    }
   },
   "outputs": [],
   "source": [
    "no_topics = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* instantiate a TfidfVectorizer with the following parameters:\n",
    "\n",
    "\n",
    "    * max_df = 0.95\n",
    "    * min_df = 2\n",
    "    * max_features = no_features\n",
    "    * stop_words = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:17.892838Z",
     "start_time": "2020-04-29T12:18:17.888668Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use fit_transform method of TfidfVectorizer to transform the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:21.486038Z",
     "start_time": "2020-04-29T12:18:19.135830Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = tfidf_vector.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* get the features names from TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:22.661253Z",
     "start_time": "2020-04-29T12:18:22.656169Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_feature_names = tfidf_vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* instantiate NMF and fit transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:24.532755Z",
     "start_time": "2020-04-29T12:18:23.661009Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF().fit(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA w/ Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* instantiate a CountVectorizer with following parameters:\n",
    "\n",
    "\n",
    "    * max_df = 0.95\n",
    "    * min_df = 2\n",
    "    * max_features = no_features\n",
    "    * stop_words = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:25.547906Z",
     "start_time": "2020-04-29T12:18:25.540452Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_vector = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use fit_transform method of CountVectorizer to transform documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:29.307223Z",
     "start_time": "2020-04-29T12:18:26.637153Z"
    }
   },
   "outputs": [],
   "source": [
    "tf = tf_vector.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* get the features names from TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:31.516381Z",
     "start_time": "2020-04-29T12:18:31.498740Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_feature_names = tf_vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* instantiate LatentDirichletAllocation and fit transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:19:03.315322Z",
     "start_time": "2020-04-29T12:18:32.768365Z"
    }
   },
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation().fit(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create a function `display_topics` that is able to display the top words in a topic for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:19:04.476192Z",
     "start_time": "2020-04-29T12:19:04.469045Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f'Topic {topic_idx}:')\n",
    "        print(' '.join([feature_names[i] for i in topic.argsort()[:no_top_words -1:1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* display top 10 words from each topic from NMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:19:05.672461Z",
     "start_time": "2020-04-29T12:19:05.656545Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "00 run right really read question program problem probably\n",
      "Topic 1:\n",
      "00 right really read question program problem probably power\n",
      "Topic 2:\n",
      "00 run right really read question program problem probably\n",
      "Topic 3:\n",
      "00 run right really read question program problem probably\n",
      "Topic 4:\n",
      "00 really read question program problem probably power point\n",
      "Topic 5:\n",
      "00 run right really read question program problem probably\n",
      "Topic 6:\n",
      "00 right really read question program problem probably power\n",
      "Topic 7:\n",
      "00 really read question program problem probably power point\n",
      "Topic 8:\n",
      "00 run right really read question program problem probably\n",
      "Topic 9:\n",
      "00 run right really read question program problem probably\n",
      "Topic 10:\n",
      "00 right really read question program problem probably power\n",
      "Topic 11:\n",
      "00 right really read question program problem probably power\n",
      "Topic 12:\n",
      "00 really read question program problem probably power point\n",
      "Topic 13:\n",
      "00 really read question program problem probably power point\n",
      "Topic 14:\n",
      "00 run right really read question program probably point\n",
      "Topic 15:\n",
      "00 right really read question problem probably point people\n",
      "Topic 16:\n",
      "00 right really read question program problem probably power\n",
      "Topic 17:\n",
      "00 right really read question program problem probably power\n",
      "Topic 18:\n",
      "00 run right really read question program problem probably\n",
      "Topic 19:\n",
      "00 right really read question program problem probably power\n",
      "Topic 20:\n",
      "00 run right really read question program problem probably\n",
      "Topic 21:\n",
      "00 read question program problem probably power point people\n",
      "Topic 22:\n",
      "00 right really read question program problem probably power\n",
      "Topic 23:\n",
      "00 run really read question program problem probably power\n",
      "Topic 24:\n",
      "00 right read question program probably power point people\n",
      "Topic 25:\n",
      "00 run right really read question program problem probably\n",
      "Topic 26:\n",
      "00 run right really read question program problem probably\n",
      "Topic 27:\n",
      "00 right really read question program problem probably power\n",
      "Topic 28:\n",
      "00 right really read question program problem probably power\n",
      "Topic 29:\n",
      "00 run right really read question program problem probably\n",
      "Topic 30:\n",
      "00 right read question problem probably power point people\n",
      "Topic 31:\n",
      "00 run right read question program problem probably power\n",
      "Topic 32:\n",
      "00 right really read question program problem probably power\n",
      "Topic 33:\n",
      "00 right really read question program problem probably power\n",
      "Topic 34:\n",
      "00 right read question program problem probably point people\n",
      "Topic 35:\n",
      "00 run right really read question program problem probably\n",
      "Topic 36:\n",
      "00 really read question program problem probably power point\n",
      "Topic 37:\n",
      "00 run right really read question problem probably power\n",
      "Topic 38:\n",
      "00 right really read question program problem probably power\n",
      "Topic 39:\n",
      "00 right really read question program problem probably power\n",
      "Topic 40:\n",
      "00 right read question program problem probably power point\n",
      "Topic 41:\n",
      "00 right really read question program problem probably power\n",
      "Topic 42:\n",
      "00 run right really read program problem probably power\n",
      "Topic 43:\n",
      "00 run right really read question program problem power\n",
      "Topic 44:\n",
      "00 run right really read question program problem probably\n",
      "Topic 45:\n",
      "00 right really read question problem probably power point\n",
      "Topic 46:\n",
      "00 right really read question program problem probably power\n",
      "Topic 47:\n",
      "00 right really read question program problem probably power\n",
      "Topic 48:\n",
      "00 read question problem probably power point people number\n",
      "Topic 49:\n",
      "00 really read question program problem probably power point\n",
      "Topic 50:\n",
      "00 really read question program problem probably power point\n",
      "Topic 51:\n",
      "00 right really read question program problem probably point\n",
      "Topic 52:\n",
      "00 right really read question program problem probably power\n",
      "Topic 53:\n",
      "00 right really read question program problem probably point\n",
      "Topic 54:\n",
      "00 right read question program problem probably power point\n",
      "Topic 55:\n",
      "00 right read question program problem probably power point\n",
      "Topic 56:\n",
      "00 run right really read question program problem probably\n",
      "Topic 57:\n",
      "00 run right really read question program problem probably\n",
      "Topic 58:\n",
      "00 run right really question program problem probably power\n",
      "Topic 59:\n",
      "00 run right really read question program problem probably\n",
      "Topic 60:\n",
      "00 right really read question program problem probably power\n",
      "Topic 61:\n",
      "00 run right really read question program problem probably\n",
      "Topic 62:\n",
      "00 right really read question program problem probably power\n",
      "Topic 63:\n",
      "00 right really read question program problem probably point\n",
      "Topic 64:\n",
      "00 run right really read question program problem probably\n",
      "Topic 65:\n",
      "00 run right really read question program problem probably\n",
      "Topic 66:\n",
      "00 right really read question program problem probably power\n",
      "Topic 67:\n",
      "00 said run really read question program problem probably\n",
      "Topic 68:\n",
      "00 run right read question program problem probably power\n",
      "Topic 69:\n",
      "list run right really read question program problem probably\n",
      "Topic 70:\n",
      "00 run right read question program problem probably power\n",
      "Topic 71:\n",
      "00 right really read question program probably power point\n",
      "Topic 72:\n",
      "00 run right really read question program problem probably\n",
      "Topic 73:\n",
      "00 really read question program problem probably power point\n",
      "Topic 74:\n",
      "00 run right read question program problem probably power\n",
      "Topic 75:\n",
      "00 read question program problem probably power point people\n",
      "Topic 76:\n",
      "00 run right really read question program problem probably\n",
      "Topic 77:\n",
      "00 really read question program problem probably power point\n",
      "Topic 78:\n",
      "00 really read question program problem probably power point\n",
      "Topic 79:\n",
      "00 really read question probably power point people number\n",
      "Topic 80:\n",
      "00 right read question program problem probably power point\n",
      "Topic 81:\n",
      "00 run right really read question program problem probably\n",
      "Topic 82:\n",
      "00 right really read question program problem probably power\n",
      "Topic 83:\n",
      "00 right really read question program problem probably power\n",
      "Topic 84:\n",
      "00 really read question program probably power point people\n",
      "Topic 85:\n",
      "00 read question program problem probably power point people\n",
      "Topic 86:\n",
      "00 run really read question program problem probably power\n",
      "Topic 87:\n",
      "00 number new mr max mail ll power year\n",
      "Topic 88:\n",
      "00 right really read question program problem probably power\n",
      "Topic 89:\n",
      "list file say god run good got government help\n",
      "Topic 90:\n",
      "00 right really read question program problem probably power\n",
      "Topic 91:\n",
      "00 read question program problem probably power point people\n",
      "Topic 92:\n",
      "00 right read question program problem probably people need\n",
      "Topic 93:\n",
      "00 right really read question program problem probably power\n",
      "Topic 94:\n",
      "00 probably power point number new mr max make\n",
      "Topic 95:\n",
      "00 program probably power point people new make question\n",
      "Topic 96:\n",
      "00 really read question program problem probably power point\n",
      "Topic 97:\n",
      "00 file g9v good got government jesus just key\n",
      "Topic 98:\n",
      "00 g9v god good government information jesus just law\n",
      "Topic 99:\n",
      "00 run right really read program problem power point\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* display top 10 words from each topic from LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:19:06.842806Z",
     "start_time": "2020-04-29T12:19:06.831721Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "ax g9v a86 b8f file government drive windows data\n",
      "Topic 1:\n",
      "ax b8f g9v a86 00 windows jesus space file\n",
      "Topic 2:\n",
      "g9v b8f a86 ax jesus god law government said\n",
      "Topic 3:\n",
      "b8f ax g9v a86 jesus god mr 00 said\n",
      "Topic 4:\n",
      "b8f ax g9v a86 god jesus drive space power\n",
      "Topic 5:\n",
      "jesus course law com probably drive god does edu\n",
      "Topic 6:\n",
      "ax a86 g9v b8f jesus god space file software\n",
      "Topic 7:\n",
      "g9v b8f a86 ax jesus god drive mr windows\n",
      "Topic 8:\n",
      "ax g9v b8f a86 max 00 file data drive\n",
      "Topic 9:\n",
      "a86 g9v ax b8f jesus god file data windows\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda, tfidf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretch: Use LDA w/ Gensim to do the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Guide](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
