{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practicing Neural Networks with the fashion MNIST dataset\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the fashion MNIST data \n",
    "The data can be loaded directly from keras (`keras.datasets.fashion_mnist`).\n",
    "\n",
    "```python\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "# returns 4 numpy arrays: 2 training sets and 2 test sets\n",
    "# images: 28x28 arrays, pixel values: 0 to 255\n",
    "# labels: array of integers: 0 to 9 => class of clothings\n",
    "# Training set: 60,000 images, Testing set: 10,000 images\n",
    "\n",
    "# class names are not included, need to create them to plot the images  \n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import io\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "%load_ext tensorboard\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "from datetime import datetime\n",
    "import io\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns 4 numpy arrays: 2 training sets and 2 test sets\n",
    "# images: 28x28 arrays, pixel values: 0 to 255\n",
    "# labels: array of integers: 0 to 9 => class of clothings\n",
    "# Training set: 60,000 images, Testing set: 10,000 images\n",
    "\n",
    "fashion_mnist = fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class names are not included, need to create them to plot the images  \n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "### Data Exploration\n",
    "\n",
    "- **Task 1:** Explore the pictures and labels. \n",
    "    - Try [displaying a picture](https://www.tensorflow.org/tensorboard/image_summaries) of each class in jupyter.\n",
    "    \n",
    "    \n",
    "- **Task 2:** Normalize the data to be between 0 and 1. \n",
    "    - Write down in a new markdown cell, **why** should we do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Display a Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (28, 28)\n",
      "Label: 9 -> Ankle boot\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape: {train_images[0].shape}')\n",
    "print(f'Label: {train_labels[0]} -> {class_names[train_labels[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the image for the Summary API.\n",
    "img = np.reshape(train_images[0], (1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out any prior log data.\n",
    "# !rm -rf logs\n",
    "\n",
    "# Sets up a timestamped log directory.\n",
    "logdir = \"logs/train_data/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Using the file writer, log the reshaped image.\n",
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"Training data\", img, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show single image in tensorboard\n",
    "# %tensorboard --logdir logs/train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show multiple images in tensorboard\n",
    "# with file_writer.as_default():\n",
    "#   # Don't forget to reshape.\n",
    "#   images = np.reshape(train_images[0:25], (1, 28, 28, 1))\n",
    "#   tf.summary.image(\"25 training data examples\", images, max_outputs=25, step=0)\n",
    "\n",
    "# %tensorboard --logdir logs/train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Normalize the Date Betwee 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***[Why](https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/):***\n",
    "\n",
    "Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. \n",
    "\n",
    "As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255\n",
    "test_images = test_images / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "### Training NN model \n",
    "\n",
    "[Guide](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/)\n",
    "\n",
    "Step 1  -  Build the architecture\n",
    "\n",
    "Step 2  -  Compile the model \n",
    "\n",
    "Step 3  -  Train the model\n",
    "\n",
    "Step 4  -  Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8631\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8653\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8668\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8688\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8701\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8710\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8718\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8740\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20953787fd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(train_images, train_labels, batch_size=1000, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 533us/step - loss: 0.4083 - accuracy: 0.8548\n",
      "test_acc: 0.8547999858856201\n",
      "test_loss: 0.40830937027931213\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'test_acc: {test_acc}\\ntest_loss: {test_loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
